---
title: "Project2"
author: "Victor Chien"
date: "4/28/2020"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

##Websites Used (research):
Health impacts of climate change: https://www.niehs.nih.gov/research/programs/geh/climatechange/health_impacts/asthma/index.cfm

Financing Healthcare: https://ourworldindata.org/financing-healthcare

PM 2.5: https://blissair.com/what-is-pm-2-5.htm

Report on healthcare financing: http://dcp-3.org/sites/default/files/resources/Global%20Health%202035%20Report.pdf


##Databases Used:
Financing Healthcare Data (from The World Health Organization's National Health Accounts): https://apps.who.int/nha/database/Home/Index/en

Pollution Data: https://data.worldbank.org/

Our World in Data (not used, contains data on testing but is incomplete): https://github.com/owid/covid-19-data/tree/master/public/data/


```{r}
#COVID Data
library(tidyverse)
library(readxl)
covid <- read_excel("C:\\Users\\Victor Chien\\Documents\\University of Texas at Austin\\Junior\\SDS 348 Computational Bio & Bioinformatics\\COVID-19_2020-04-27.xlsx")

#Fix covid Data
covid <- covid %>% arrange(countryterritoryCode,dateRep) %>% group_by(countryterritoryCode) %>%
  mutate(cum_cases = cumsum(cases),
         cum_deaths = cumsum(deaths), 
         mortality_percent = (cum_deaths/cum_cases)*100,
         prop_infect = cum_cases/popData2018, 
         GF = cases/lag(cases) %>% round(4), #Growth Factor
         )

is.na(covid$GF) <- sapply(covid$GF, is.infinite) #replace inf with NA
covid$GF[is.na(covid$GF)] <- 0 #replace NaN and NA with 0

#GF rolling mean of last week
covid <- covid %>% mutate(meanGFoflastweek = (GF+lag(GF,1)+lag(GF,2)+lag(GF,3)+lag(GF,4)+lag(GF,5)+lag(GF,6))/7) 

#Arbitrarily define containment (can be modified to fit a better model)
covid2 <- covid %>% filter(dateRep == max(dateRep)) %>% select(countriesAndTerritories:meanGFoflastweek) %>% 
  mutate(contained = ifelse(meanGFoflastweek < 1 & cum_cases > 400,1,0)) %>% na.omit #omit five rows with no country code

#summary of containment
covid2 %>% ungroup() %>% summarize("Countries Contained" = sum(contained), "Total Countries" = n())
```


```{r}
#Read Datasets

#Healthcare Data (WHO NHA)
health <- read_excel("C:\\Users\\Victor Chien\\Documents\\University of Texas at Austin\\Junior\\SDS 348 Computational Bio & Bioinformatics\\NHA Indicators with Region and Income.xlsx")

#Pollution Data (World Bank)
pollution <- read_excel("C:\\Users\\Victor Chien\\Documents\\University of Texas at Austin\\Junior\\SDS 348 Computational Bio & Bioinformatics\\World Bank Pollution.xlsx")


#Merge Datasets
merged <- covid2 %>%
  left_join(health, by = c("countryterritoryCode" = "Code")) %>%
  left_join(pollution, by = c("countryterritoryCode" = "Country Code"))

#Select and Rename Necessary Variables
merged2 <- merged %>% select(countryterritoryCode,`Country Name`,countryterritoryCode,contained,Region,Income,
                  "Mortality" = mortality_percent,
                  "CHE"=`Current Health Expenditure (CHE) as % Gross Domestic Product (GDP)`,
                  "GGHE-D"=`Domestic General Government Health Expenditure (GGHE-D) as % Current Health Expenditure (CHE)`,
                  "PVT-D"=`Domestic Private Health Expenditure (PVT-D) as % Current Health Expenditure (CHE)`,
                  "CO2"=`CO2 emissions (kt) 2014`,
                  "N2O"=`Nitrous oxide emissions (thousand metric tons of CO2 equivalent) 2012`,
                  "PM2.5"=`PM2.5 air pollution, mean annual exposure (micrograms per cubic meter) 2017`,
                  "Smoking"=`Smoking prevalence, total (ages 15+) 2016`
                  )
glimpse(merged2)
unique(merged2$Region)
unique(merged2$Income)
```

The merged2 dataset contains data from 3 separate datasets. The first dataset (covid) employs the "contained" variable using data on COVID-19. A "Growth Factor" was calculated by dividing the number of new cases in one day by the number of new cases in the prior day. The rolling average of the previous week was calculated for each day and the most recent (2020-04-27) data point's rolling mean GF was collected for each country. A country has contained COVID-19 (1) if the rolling mean GF is less than one AND if the cumulative number of cases is greater than 400 (arbitrary; used to filter out countries that haven't been infected with COVID-19).

The second dataset (health) includes healthcare financing statistics. CHE (current health expenditure) measures how much of a country's GDP is spent on health. GGHE-D (Domestic General Government Health Expenditure) measures how much of the CHE is sourced from public health insurance and PVT-D (Domestic Private Health Expenditure) measures how much of the CHE is sourced from private health insurance.

The third dataset (pollution) contains four metrics of environmental pollution before coronavirus including CO2 emission (kt) from 2014, N2O emission (kt-CO2 eqivalents) from 2012, PM2.5 (ug/m^3) from 2017, and smoking prevalence (%) from 2016. These are the primary greenhouse gases that several federal and world health authorities have deemed cause respiratory problems and lead to premature death. Although worldwide quarantines have temporarily reduced emission of harmful pollutants, populations with long-term exposure to high levels of pollution prior to the pandemic should theoretically be at higher risk. Thus, mortality rate has also been included.


This project is meant to be a continuation of project 1, using new variables to model the likelihood of a country's ability to contain COVID-19. The final merged2 dataset contains 202 observations with each country as its own row. The categorical variables Region and Income have been included for each Country, whose 3-letter country codes were used to join the datasets.


```{r, fig.width=12}
#MANOVA by Region
man1 <- manova(cbind(Mortality,CHE,`GGHE-D`,`PVT-D`,CO2,N2O,PM2.5,Smoking)~Region, data=merged2)
summary(man1)
summary.aov(man1)
pairwise.t.test(merged2$Mortality, merged2$Region, p.adj = "none")
pairwise.t.test(merged2$CHE, merged2$Region, p.adj = "none")
pairwise.t.test(merged2$`GGHE-D`, merged2$Region, p.adj = "none")
pairwise.t.test(merged2$`PVT-D`, merged2$Region, p.adj = "none")
pairwise.t.test(merged2$PM2.5, merged2$Region, p.adj = "none")
pairwise.t.test(merged2$Smoking, merged2$Region, p.adj = "none")

#MANOVA by Income (For s**** and giggles)
man2 <- manova(cbind(Mortality,CHE,`GGHE-D`,`PVT-D`,CO2,N2O,PM2.5,Smoking)~Income, data=merged2)
summary(man2)
summary.aov(man2)
pairwise.t.test(merged2$`GGHE-D`,merged2$Income)

#Multivariate Plots
ggplot(merged2, aes(x = Smoking, y = `PVT-D`)) +
geom_point(alpha = .5) + geom_density_2d(h=20) + coord_fixed() + facet_wrap(~Region) 
ggplot(merged2, aes(x = Mortality, y = CHE)) +
geom_point(alpha = .5) + geom_density_2d(h=10) + coord_fixed() + facet_wrap(~Region)

```

Two categorical variables, Region and Income, were found, so MANOVAs for each were performed. For both, there is a significant difference between groups in at least one variable. However, since we are interested in comparing different countries' responses to COVID-19 we will only be comparing means by Region. There are many variables to be tested (84 hypothesis tests), so our Type-I Error Rate is very high: 98.65%. We must use the Bonferroni correction alpha = 5.952e-4 to evaluate significance.
Within Mortality, no region's mortality rate is significantly different using the Bonferroni correction.
Within CHE, Europe differs with Africa and South East Asia.
Within GGHE-D, Africa differs from the Americas, Europe, and Western Pacific.
Within PVT-D, no region's PVT-D is significantly different from one another.
Within PM2.5, Africa differs all regions except SE Asia. The Americas differ from Africa, Eastern Mediterranean, and SE Asia. The Eastern Mediterranean differs with all regions except SE Asia. Europe differs from Africa, Eastern Mediteranean, and SE Asia. SE Asia differs from the Americas and Europe. 
Within Smoking, Africa differs from Europe, SE Asia, and Western Pacific. The Americas differ from Europe, SE Asia, and Western Pacific.

Because we are examining data from all countries, many variables do not have a proper normal distribution. For example, looking at the multivariate plot with PVT-D and Smoking, we can see that these variables vary quite a bit depending on government and cultural norms. 
From the multivariate plot with CHE and Mortality, we can see that most mortality rates are in fact centered between 0% and 10%, however, the graphs have outliers with mortality skewed to the right since mortality can increase all the way to 100% but cannot go under 0%. 
Although these are separate and independent countries, they may not be completely independent observations since borders are fluid and cultural norms (smoking prevalence), COVID-19 (mortality), and ideas about government norms (CHE) may travel across borders. Pollution statistics especially, since they are measures of air quality, can link countries in close geographic proximity.


```{r} 
#Randomization Test
anovaData <- merged2 %>% select(Income,`GGHE-D`) %>% na.omit() %>% ungroup()#new dataset to omit NAs
anovaData %>% group_by(Income) %>% summarize(n(), mean=mean(`GGHE-D`,na.rm = T)) #number of obs and means per group

summary(aov(`GGHE-D`~Income, data=anovaData)) #Obs F = 58.82
pairwise.t.test(anovaData$`GGHE-D`,anovaData$Income, p.adj = "none") #p-values

#The Actual Randomization Test...
obs_F <- 58.82
Fs <- replicate(5000,{ 
new<- anovaData %>% mutate(`GGHE-D` = sample(`GGHE-D`)) #randomly permute response variable

SSW <- new %>% group_by(Income) %>% summarize(SSW=sum((`GGHE-D`-mean(`GGHE-D`))^2)) %>%
  summarize(sum(SSW)) %>% pull
SSB <- new %>% mutate(mean=mean(`GGHE-D`)) %>% group_by(Income) %>% mutate(groupmean=mean(`GGHE-D`)) %>%
  summarize(SSB=sum((mean-groupmean)^2)) %>% summarize(sum(SSB)) %>% pull

(SSB/3)/(SSW/165) #compute F statistic (num df = K-1 = 4-1, denom df = N-K = 169-4)
})

hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F) #p-value
```

Since we evaluated the MANOVA by Region in the previous section, we will be looking at variables by Income group for our Randomization Test. Running some preliminary tests, we see that GGHE-D varies widely based on Income group of a country, so we will be running a randomization ANOVA for GGHE-D by Income group under these hypotheses...

Null Hypothesis: There is no difference in GGHE-D means between any income group.
Alternative Hypothesis: At least one of the means differ from the others

Our observed F-statistic is 58.82. From the histogram of generated F statistics, we can see that no F-statistics are anywhere close to 58.82, thus, the p-value is effectively 0. We reject the null hypothesis and conclude that at least one of the means differ from the others.


```{r}
#Linear Regression
linearData_c <- merged2 %>% ungroup() %>% select(CHE,`GGHE-D`,`PVT-D`,CO2,N2O,PM2.5,Smoking,-countryterritoryCode) %>% scale(scale=FALSE) %>% as.data.frame()
linearData_c$Mortality <- merged2 %>% ungroup() %>% select(Mortality = Mortality) %>% unlist() %>% as.numeric


linear1 <- lm(Mortality ~ CHE+N2O+CO2+Smoking, data=linearData_c)
summary(linear1)
linear2 <- lm(Mortality ~ CHE*N2O*CO2*Smoking, data=linearData_c)
summary(linear2)
```

A linear regression has been run on four predictor variables (CHE, N2O, CO2, and Smoking) and its effect on Mortality rate, so there are many coefficients in our model. 
Keep in mind that these variables have different units and are centered at the mean: 
CHE - Current Health Expenditure as a % of GDP
N2O - kilotonnes of CO2 equivalents emitted
CO2 - kilotonnes emitted
Smoking - Prevalence as a % of population
Mortality - % of COVID-19 deaths out of the number of confirmed cases

Thus, for a country that has the mean value of each predictor variable, the predicted mortality rate is 4.177%. For every 1% of GDP increase in health expenditure, predicted mortality increases by 0.5162%. For every 1kt increase in N2O, mortality increases by a measly 0.000037%. For every 1kt increase in CO2, mortality increases by an even smaller 0.000002%. For every 1% increase in smoking prevalence, mortality increases by 0.1169%.
For two variable interactions, a 1 unit increase in both variables will change the mortality by a percentage as indicated by the coefficients. For example, a 1% of GDP increase in CHE and a 1kt increase in N2O will increase mortality by 5.330e-6%.
For three variable interactions, a 1 unit increase in all 3 variables will change mortality by a percent indicated by the coefficient. For example, a 1 unit increase in CHE, N2O, and CO2 increases mortality by 1.390e-12%.
For the four variable interaction, a 1 unit increase in all 4 predictor variables actually decreases mortality by 0.9864e-12%.
There are 16 of these coefficients, so I've only provided a few examples. Since these variables are mean centered, if a value is less than the mean, the predicted mortality rate changes in the opposite direction notated by the coefficients.


```{r}
#Linear Regression Continued

#Plot Regression
fit <- lm(Mortality ~ CHE*CO2*N2O*Smoking, data=linearData_c)
new1 <- linearData_c

new1$Smoking<-mean(linearData_c$Smoking, na.rm = T)
new1$mean<-predict(fit,new1)
new1$Smoking<-mean(linearData_c$Smoking, na.rm = T)+sd(linearData_c$Smoking, na.rm = T)
new1$plus.sd<-predict(fit,new1)
new1$Smoking<-mean(linearData_c$Smoking, na.rm = T)-sd(linearData_c$Smoking, na.rm = T)
new1$minus.sd<-predict(fit,new1)

newint <- new1 %>% select(Mortality,CHE,Smoking,mean,plus.sd,minus.sd) %>% gather(Smoking,value,-Mortality,-CHE)

mycols<-c("#619CFF","#F8766D","#00BA38")
names(mycols)<-c("-1 sd","mean","+1 sd")
mycols=as.factor(mycols)

ggplot(linearData_c,aes(x=CHE,y=Mortality),group=mycols)+geom_point()+
  geom_line(data=new1,aes(y=mean,color="mean"))+
  geom_line(data=new1,aes(y=plus.sd,color="+1 sd"))+
  geom_line(data=new1,aes(y=minus.sd,color="-1 sd"))+
  scale_color_manual(values=mycols)+labs(color="Smoking")+
  theme(legend.position=c(.9,.8)) +
  scale_y_continuous(limits = c(0,25))

#Check Assumptions
library(lmtest)
resids <- fit$residuals
fitvals <- fit$fitted.values
bptest(fit) #linearity, homoscedasticity
ks.test(resids, "pnorm", mean=0, sd(resids)) #normality

#Robust Standard Errors
library(sandwich)
coeftest(fit,vcov = vcovHC(fit)) 

#Proportion of Variation Explained
summary(fit)


```

Using the studentized Breusch-Pagan test, we fail to reject the null hypothesis that the residuals are homoscedastic (BP = 8.3349, df = 15, p-value = 0.9097), therefore, the residuals are homoscedastic.
Using the one-sample Kolmogorov-Smirnov test, we fail to reject the null hypothesis that the data is normally distributed (D = 0.1071, p-value = 0.09679), therefore, the data is normally distributed.

After recomputing the regression with robust standard errors, every item that was significant is no longer significant. While the coefficients stayed the same, standard errors increased because robust standard errors are used when the residuals are heteroscedastic (violating an assumption). This decreases t-values and increases p-values. There are, however, 3 coefficients that have a p-value < 0.10. These are CHE, N2O:Smoking, and CHE:N2O:Smoking, which are almost but not quite significant under alpha = 0.05.

According to the adjusted R-squared, the original model explains 20.13% of the variation in the outcome.

```{r}
#Bootstrapped Standard Error
samp_distn <- replicate(5000, {
boot_dat <- sample_frac(linearData_c, replace=T) #bootstrap data
fit <- lm(Mortality ~ CHE*CO2*N2O*Smoking, data=boot_dat) #fit model
coef(fit) #save coefs
})
## Estimated SEs
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd) %>% t
```

The bootstrapped SEs are greater than the original SEs for each coefficient. This means that the p-values are also larger so our coefficients will be less significant. The bootstrapped SEs are similar to the robust SEs with some slightly larger and others slightly smaller. The p-values of the boostrapped data should be pretty close to those of the model using robust SEs.

```{r}
#Logistic Regression
logistic <- glm(contained ~ CHE+`GGHE-D`+`PVT-D`+CO2+N2O+PM2.5+Smoking ,data=merged2, family = binomial)
summary(logistic)

exp(coef(logistic)) 
```

The coefficients of the logistic regression are log odds, so we have exponentiated coefficients to reflect odds. For every 1% of GDP increase in CHE, the odds of containment increases by a factor of 1.217. For every 1% of CHE increase in Government Health Expenditure (GGHE-D), the odds of containment increases by a factor of 1.05. For every 1% of CHE increase in Private Health Expenditure (PVT-D), the odds of containment increases by a factor of 1.014. The odds of containment changes very little for each 1kt increase in CO2 or N2O - only by a factor of 0.99999. For every 1 micrograms per cubic meter increase in PM2.5, the odds of containment increases by a factor of 1.013. For every 1% increase in smoking prevalence, the odds of containment decreases by a factor of 0.9622.
Note that factors can be changed to percentage change by subtracting 1 and multiplying by 100. For example a 1% of GDP increase in CHE increases the odds of containment by 21.7%.

```{r}
#Logistic Regression Continued

prob <- predict(logistic, type = "response") %>% as.vector()
truth <- merged2 %>% na.omit
table(truth$contained, prediction=as.numeric(prob>0.5))%>%addmargins

class_diag <- function(probs,truth){
  
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

class_diag(prob,truth$contained)

```

The model is relatively accurate, however we can see from the confusion matrix that many of the actual contained countries (1) are predicted not contained (0) as reflected by a very low sensitivity/true positive rate. The specificity/true negative rate is high since the model has predicted 0 for most country containments. The positive predictive value is also rather poor since the model did not predict many 1s. The AUC for this model is 0.726, which is fair.


```{r}
#Density Plot
logisticData <- merged2 %>% na.omit() %>% ungroup() %>% as.data.frame()
logisticData$logit <- predict(logistic,type="link")

logisticData <- logisticData %>% mutate(outcome = ifelse(contained == 1,"contained","not contained"))
logisticData$outcome <- factor(logisticData$outcome,levels=c("contained","not contained")) 

glimpse(logisticData)

logisticData %>% ggplot()+geom_density(aes(logit,color=outcome,fill=outcome), alpha=.4)+
  geom_vline(xintercept=0)+
  xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=outcome))


#ROC Curve
library(plotROC)
logisticData$prob <- predict(logistic, type="response")

ROC <- ggplot(logisticData) +
  geom_roc(aes(d=outcome,m=prob), n.cuts = 0) +
  xlab("FPR") +
  ylab("TPR")
ROC
calc_auc(ROC)
```

The density plot above shows significant overlap between contained and not contained.
This is reflected in a low AUC of 0.2739, which is very poor. This means that our model is not a good predictor of whether a country contains COVID-19 at all.

```{r}
#10-fold CV
set.seed(1234)
k=10

data <- merged2 %>% sample_frac %>% na.omit  #put rows of dataset in random order
folds <- ntile(1:nrow(data),n=10) #create fold labels

diags<-NULL
for(i in 1:k){
train <- data[folds!=i,] #create training set (all but fold i)
test <- data[folds==i,] #create test set (just fold i)
truth <- test$contained #save truth labels from fold i
fit <- glm(contained ~ CHE+`GGHE-D`+`PVT-D`+CO2+N2O+PM2.5+Smoking ,data=train, family = "binomial")
probs <- predict(fit, newdata=test, type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)



```

Accuracy: 0.733
Sensitivity: 0.033
AUC: 0.593
Once again, the model does a poor job predicting containment for countries who actually have contained COVID-19 (based on our guidelines).

```{r}
#LASSO Regression
library(glmnet)
y<-as.matrix(data$contained) #grab response
x<-model.matrix(contained ~ CHE+`GGHE-D`+`PVT-D`+CO2+N2O+PM2.5+Smoking,data=data)[,-1] #grab predictors
x<-scale(x)
cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)

#10-fold CV on LASSO
set.seed(1234)
k=10
data <- merged2 %>% sample_frac %>% na.omit #put rows of dataset in random order
folds <- ntile(1:nrow(data),n=10) #create fold labels
diags<-NULL
for(i in 1:k){
train <- data[folds!=i,] #create training set (all but fold i)
test <- data[folds==i,] #create test set (just fold i)
truth <- test$contained #save truth labels from fold i
fit <- glm(contained~CHE,
data=train, family="binomial")
probs <- predict(fit, newdata=test, type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)

```

The LASSO accuracy increased slightly from 0.733 to 0.763. However, only the predictor variable CHE was retained and the LASSO matrix shows 0... In fact, the sensitivity is now 0. The AUC decreased only slight, but it is still a poor model for containment. 

For further statistical analyses, containment criterion should be modified, only countries with a lower limit of confirmed cases should be included, and the merged dataset should not have any missing values for predictor variables (since the entire country would be omitted for a single NA).


```{r pressure, echo=FALSE}
sessionInfo()
Sys.time()
Sys.info()
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
